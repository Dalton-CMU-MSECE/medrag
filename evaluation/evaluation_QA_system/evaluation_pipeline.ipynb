{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.pipeline.med_rag import MedicalRAGPipeline\n",
    "from evaluation.evaluation_QA_system.RAG_evaluator import RAGEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff248dc",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../../configs/pipeline_config.yaml'\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3731e",
   "metadata": {},
   "source": [
    "## Initialize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MedicalRAGPipeline(config)\n",
    "print(\"Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ab5cc",
   "metadata": {},
   "source": [
    "## Load Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test queries (example format)\n",
    "test_queries = [\n",
    "    {\n",
    "        \"query\": \"What are the symptoms of COVID-19?\",\n",
    "        \"relevant_docs\": [\"doc1\", \"doc2\"],\n",
    "        \"reference_answer\": \"COVID-19 symptoms include fever, cough, and fatigue.\"\n",
    "    },\n",
    "    # Add more test queries here\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(test_queries)} test queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f32b05",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a99949",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RAGEvaluator()\n",
    "predictions = []\n",
    "\n",
    "for test_query in test_queries:\n",
    "    result = pipeline.process_query(test_query[\"query\"])\n",
    "    predictions.append(result)\n",
    "\n",
    "print(f\"Processed {len(predictions)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d55dd8",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.evaluate_batch(predictions, test_queries)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00659397",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084674be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '../evaluation_data_storages/evaluation_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'metrics': metrics,\n",
    "        'predictions': predictions\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {results_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
